{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b6b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fddbcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"new.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"targetdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808f0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, preprocessing, utils\n",
    "import yaml\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daf655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 1134\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'C:/Users/dell/Documents/WISE/new/new/data'\n",
    "files_list = os.listdir(dir_path + os.sep)# list all files in dir\n",
    "\n",
    "questions = list()\n",
    "answers = list()\n",
    "\n",
    "for filepath in files_list:\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')# read each file in dir\n",
    "    docs = yaml.safe_load(stream) # full data\n",
    "    conversations = docs['conversations']#send all docs to conversations\n",
    "    for con in conversations:#each line\n",
    "        if len( con )> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "#This class allows to vectorize a text corpus, by turning each text into either a \n",
    "#sequence of integers (each integer being the index of a token in a dictionary)\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "#The cat sat on the mat.\" It will create a dictionary , word_index[\"the\"] = 1; word_index[\"cat\"] = 2\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aba7285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\anaconda3\\envs\\tensor_flow_env\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dell\\anaconda3\\envs\\tensor_flow_env\\lib\\site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\dell\\anaconda3\\envs\\tensor_flow_env\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\dell\\anaconda3\\envs\\tensor_flow_env\\lib\\site-packages (from gensim) (0.29.21)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\dell\\anaconda3\\envs\\tensor_flow_env\\lib\\site-packages (from gensim) (1.18.5)\n",
      "thiazolidinediones\n",
      "852\n",
      "(312, 54) 54\n",
      "(312, 55) 55\n",
      "(312, 55, 1134)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\envs\\tensor_flow_env\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "from gensim.models import Word2Vec#learns rel btwn words automatically\n",
    "\n",
    "vocab=[]\n",
    "for word in tokenizer.word_index:\n",
    "    vocab.append(word)\n",
    "    \n",
    "x = max(vocab, key=len)\n",
    "print(x)\n",
    "print(vocab.index(x))\n",
    "\n",
    "def tokenize(sentences):\n",
    "    tokens_list=[]\n",
    "    vocabulary=[]\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        tokens = sentence.split()\n",
    "        vocabulary+=tokens\n",
    "        tokens_list.append(tokens)\n",
    "    return tokens_list,vocabulary\n",
    "\n",
    "\n",
    "p=tokenize(questions+answers)\n",
    "model = Word2Vec(p[0])\n",
    "\n",
    "#encoder input\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "padded_questions = preprocessing.sequence.pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
    "encoder_input_data = np.array( padded_questions )\n",
    "print(encoder_input_data.shape, maxlen_questions)\n",
    "#decoder input\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "decoder_input_data = np.array(padded_answers)\n",
    "print(decoder_input_data.shape, maxlen_answers)\n",
    "#decoder output\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "for i in range(len(tokenized_answers)):\n",
    "    tokenized_answers[i]=tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "one_hot_answers = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
    "decoder_output_data = np.array(one_hot_answers)\n",
    "print(decoder_output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9915faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 852)    966168      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 852)    966168      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 852), (None, 5810640     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 852),  5810640     embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1134)   967302      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,520,918\n",
      "Trainable params: 14,520,918\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 852 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 852 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 852 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 852 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e22e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 1.3436 - accuracy: 0.1441\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.1870 - accuracy: 0.1671\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.0870 - accuracy: 0.1156\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.0428 - accuracy: 0.1998\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.0095 - accuracy: 0.2007\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.9860 - accuracy: 0.2028\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.9641 - accuracy: 0.2025\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.9571 - accuracy: 0.2084\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.9142 - accuracy: 0.2141\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.8777 - accuracy: 0.2243\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.8393 - accuracy: 0.2414\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.7963 - accuracy: 0.2633\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.7584 - accuracy: 0.2755\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.7179 - accuracy: 0.2914\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.6803 - accuracy: 0.3064\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.6430 - accuracy: 0.3235\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.6086 - accuracy: 0.3453\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.5752 - accuracy: 0.3624\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.5375 - accuracy: 0.3857\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.5002 - accuracy: 0.4199\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.4608 - accuracy: 0.4630\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.4254 - accuracy: 0.5076\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.3892 - accuracy: 0.5565\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3525 - accuracy: 0.6056\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3146 - accuracy: 0.6709\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.2834 - accuracy: 0.7062\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.2606 - accuracy: 0.7385\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.2331 - accuracy: 0.7724\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.2044 - accuracy: 0.8119\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.1778 - accuracy: 0.8416\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.1542 - accuracy: 0.8742\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.1356 - accuracy: 0.8943\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.1197 - accuracy: 0.9134\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.1044 - accuracy: 0.9236\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0912 - accuracy: 0.9332\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.0798 - accuracy: 0.9479\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.0700 - accuracy: 0.9542\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.0613 - accuracy: 0.9659\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0541 - accuracy: 0.9704\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0495 - accuracy: 0.9715\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0433 - accuracy: 0.9751\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0385 - accuracy: 0.9799\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.0351 - accuracy: 0.9832\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0318 - accuracy: 0.9850\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0287 - accuracy: 0.9865\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0264 - accuracy: 0.9883\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.0241 - accuracy: 0.9874\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0225 - accuracy: 0.9883\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.0214 - accuracy: 0.9883\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.0196 - accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=50 ) \n",
    "model.save( 'model.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a219545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 852 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 852 ,))\n",
    "    \n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e79ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd13848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "681b4749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026F0B0FF1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026F0E1C7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "def chatbot_response(msg):\n",
    "  states_values = enc_model.predict( str_to_tokens(msg) )\n",
    "  empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "  empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "  stop_condition = False\n",
    "  decoded_translation = ''\n",
    "  while not stop_condition :\n",
    "    dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "    sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "    sampled_word = None\n",
    "    for word , index in tokenizer.word_index.items() :\n",
    "      if sampled_word_index == index :\n",
    "        decoded_translation += ' {}'.format( word )\n",
    "        sampled_word = word\n",
    "        \n",
    "      if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "        stop_condition = True\n",
    "      empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "      empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "      states_values = [ h , c ]\n",
    "  return decoded_translation\n",
    "\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    \n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END,\"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END,\"MedBot: \" + res + '\\n\\n')\n",
    "\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "\n",
    "base = Tk()\n",
    "base.title(\"MedBot\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"9\", width=\"50\", font=\"Arial\",)\n",
    "ChatLog.config(state=DISABLED)\n",
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command= send )\n",
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "base.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d598f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3bfcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a319dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca004fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2582bff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb14ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adfa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679f3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf0514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0869329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5c0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e76e965a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fe3d66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5abda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e47857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
